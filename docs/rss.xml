<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Ywunothing</title><link>https://Goinghome-Chapter1.github.io</link><description>答案是我</description><copyright>Ywunothing</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://Goinghome-Chapter1.github.io</link></image><lastBuildDate>Fri, 28 Feb 2025 02:56:36 +0000</lastBuildDate><managingEditor>Ywunothing</managingEditor><ttl>60</ttl><webMaster>Ywunothing</webMaster><item><title>主流大模型工具大总结！！</title><link>https://Goinghome-Chapter1.github.io/post/zhu-liu-da-mo-xing-gong-ju-da-zong-jie-%EF%BC%81%EF%BC%81.html</link><description>### **一、大模型推理框架**

| **工具名称** | **性能表现**                                                                 | **易用性**                                                                 | **适用场景**                                                                 | **硬件需求**                                                                 | **模型支持**                                                                 | **部署方式**                                                                 | **系统支持**               |
|--------------|-----------------------------------------------------------------------------|---------------------------------------------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|---------------------------|
| **SGLang**   | - 零开销批处理提升1.1倍吞吐量&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 缓存感知负载均衡提升1.9倍&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 结构化输出提速10倍&lt;button class='citation-flag' data-index='1'&gt;&lt;br&gt;- Llama-70B吞吐量较vLLM高3.1倍（A100测试）&lt;button class='citation-flag' data-index='6'&gt;&lt;button class='citation-flag' data-index='9'&gt; | 需熟悉Python和Linux环境，配置复杂度中等&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;                          | - 企业级推理服务（如电商客服、金融分析）&lt;button class='citation-flag' data-index='1'&gt;&lt;br&gt;- 高并发场景（如千人级实时对话）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 结构化输出应用（如JSON格式生成）&lt;button class='citation-flag' data-index='1'&gt; | - **GPU**: A100/H100（推荐多卡并行）&lt;button class='citation-flag' data-index='6'&gt;&lt;button class='citation-flag' data-index='9'&gt;&lt;br&gt;- **存储**: 高速SSD（缓存模型参数）&lt;button class='citation-flag' data-index='2'&gt; | - 支持Llama、Gemma、Mistral、Qwen、DeepSeek等主流模型&lt;button class='citation-flag' data-index='8'&gt;&lt;br&gt;- 优化DeepSeek-R1-32B性能&lt;button class='citation-flag' data-index='1'&gt; | - Docker容器化部署&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- Python包集成（需自定义服务端）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 支持REST API扩展&lt;button class='citation-flag' data-index='7'&gt; | 仅Linux（Ubuntu 20.04+）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt; | &lt;button class='citation-flag' data-index='1'&gt;&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;button class='citation-flag' data-index='6'&gt;&lt;button class='citation-flag' data-index='8'&gt;&lt;button class='citation-flag' data-index='9'&gt; |
| **Ollama**   | - 继承llama.cpp高效推理能力，内存占用降低40%&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 支持动态批处理，延迟低于100ms&lt;button class='citation-flag' data-index='5'&gt; | 提供一键安装脚本和WebUI界面，小白友好&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;                            | - 个人开发者创意验证（如聊天机器人原型）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 学生辅助学习（如论文摘要生成）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 日常问答（如知识库检索）&lt;button class='citation-flag' data-index='5'&gt; | - **CPU**: 8核+（支持AVX2指令集）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- **GPU**: 可选（CUDA 11.8+）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- **内存**: 16GB+（运行70B模型需32GB+）&lt;button class='citation-flag' data-index='2'&gt; | - 1700+款模型（如Llama-3-8B、Qwen1.5）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 支持GGUF格式&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 一键下载安装&lt;button class='citation-flag' data-index='2'&gt; | - 独立应用程序（Windows/macOS/Linux）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- Docker部署（企业级场景）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- REST API（需配合第三方工具）&lt;button class='citation-flag' data-index='5'&gt; | 全平台（Windows/macOS/Linux）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt; | &lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;              |
| **VLLM**     | - PagedAttention技术减少内存碎片&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- Continuous Batching吞吐量提升24倍（对比传统批处理）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 支持8-bit量化，显存占用降低30%&lt;button class='citation-flag' data-index='5'&gt; | 需熟悉PyTorch和NVIDIA生态，配置复杂度较高&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;                         | - 大规模在线推理服务（如搜索引擎、推荐系统）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 高并发场景（如万人级实时请求）&lt;button class='citation-flag' data-index='5'&gt; | - **GPU**: NVIDIA A100/H100（必须）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- **显存**: 40GB+（运行70B模型）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- **存储**: 1TB+（模型权重缓存）&lt;button class='citation-flag' data-index='5'&gt; | - 主流Hugging Face模型（如Llama-3-70B、Mistral）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 支持自定义模型适配&lt;button class='citation-flag' data-index='5'&gt; | - Python包（pip安装）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- OpenAI兼容API（无缝替换接口）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- Docker（生产环境推荐）&lt;button class='citation-flag' data-index='2'&gt; | 仅Linux（CentOS/Ubuntu）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt; | &lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;              |
| **LLaMA.cpp**| - 多级量化（4-bit/5-bit）显存占用降低70%&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 跨平台优化，CPU推理速度提升2倍（对比早期版本）&lt;button class='citation-flag' data-index='5'&gt; | 命令行界面直观，提供预编译二进制文件&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;                              | - 边缘设备部署（如树莓派、Jetson Nano）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- 移动端应用（Android/iOS本地推理）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 本地服务（如离线文档分析）&lt;button class='citation-flag' data-index='2'&gt; | - **CPU**: 支持AVX2/FMA指令集（Intel/AMD）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- **GPU**: 可选（支持CUDA/Vulkan）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- **内存**: 8GB+（运行7B模型）&lt;button class='citation-flag' data-index='2'&gt; | - GGUF格式模型（如Llama-3-8B、Phi-3）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 社区驱动模型库（持续更新）&lt;button class='citation-flag' data-index='5'&gt; | - 命令行工具（直接运行）&lt;button class='citation-flag' data-index='2'&gt;&lt;br&gt;- API服务器（Go/Python绑定）&lt;button class='citation-flag' data-index='5'&gt;&lt;br&gt;- 多语言SDK（C/C++/Rust）&lt;button class='citation-flag' data-index='5'&gt; | 全平台（Windows/macOS/Linux/Android）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt; | &lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;              |

### **二、大模型RAG+AI工作流+Agent工具**

| **工具**          | **核心功能**                                                                 | **适用场景**                           | **优点**                                                                 | **缺点**                                                                 | **硬件需求**                                                                 |
|-------------------|-----------------------------------------------------------------------------|----------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| **MaxKB**         | 知识库问答、RAG、工作流编排（可视化拖拽）&lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='3'&gt;&lt;button class='citation-flag' data-index='5'&gt;                     | 企业内部知识管理&lt;button class='citation-flag' data-index='3'&gt;                   | 开箱即用，支持文档自动拆分与向量化&lt;button class='citation-flag' data-index='6'&gt;；无缝嵌入第三方系统&lt;button class='citation-flag' data-index='2'&gt;         | 工作流灵活性弱于Dify，复杂场景需二次开发&lt;button class='citation-flag' data-index='7'&gt;                           | **CPU**: 8核+&lt;br&gt;**内存**: 16-32GB&lt;br&gt;**显卡**: 可选（加速向量化） | &lt;button class='citation-flag' data-index='2'&gt;&lt;button class='citation-flag' data-index='5'&gt;&lt;button class='citation-flag' data-index='6'&gt;        |
| **Dify**          | Prompt编排、RAG、多模型支持、工作流API&lt;button class='citation-flag' data-index='1'&gt;&lt;button class='citation-flag' data-index='4'&gt;&lt;button class='citation-flag' data-index='8'&gt;                       | 复杂任务自动化&lt;button class='citation-flag' data-index='4'&gt;&lt;button class='citation-flag' data-index='8'&gt;                | 开源且模块化，支持从原型到生产的全链路&lt;button class='citation-flag' data-index='8'&gt;；内置50+工具（如谷歌搜索）&lt;button class='citation-flag' data-index='6'&gt; | 需一定编码能力，学习曲线较高&lt;button class='citation-flag' data-index='9'&gt;                                       | **CPU**: 16核+&lt;br&gt;**内存**: 32GB+&lt;br&gt;**显存**: 16GB+（如运行70B模型）&lt;br&gt; | &lt;button class='citation-flag' data-index='1'&gt;&lt;button class='citation-flag' data-index='8'&gt;&lt;button class='citation-flag' data-index='9'&gt;        |
| **FastGPT**       | 知识库训练、可视化工作流编排&lt;button class='citation-flag' data-index='10'&gt;                                           | 中小企业知识库构建与问答&lt;button class='citation-flag' data-index='10'&gt;          | 提供预置模板，快速构建问答系统&lt;button class='citation-flag' data-index='10'&gt;                                    | 功能相对基础，扩展性有限&lt;button class='citation-flag' data-index='10'&gt;                                          | **CPU**: 4核+&lt;br&gt;**内存**: 8-16GB | &lt;button class='citation-flag' data-index='10'&gt;                 |
| **RagFlow**       | 深度文档理解、多路召回（如PDF/表格解析）&lt;button class='citation-flag' data-index='9'&gt;                                | 专业领域（法律、医疗）数据问答&lt;button class='citation-flag' data-index='9'&gt;     | 专注复杂格式数据（如科研论文、财务报表）的高精度问答&lt;button class='citation-flag' data-index='9'&gt;                | 配置复杂，需专业领域知识&lt;button class='citation-flag' data-index='9'&gt;                                           | **CPU**: 8核+&lt;br&gt;**内存**: 32GB+&lt;br&gt;**显存**: 8GB+（处理多格式文档） | &lt;button class='citation-flag' data-index='9'&gt;                  |
| **Anything-LLM**  | 多用户支持、本地部署、隐私保护&lt;button class='citation-flag' data-index='9'&gt;                                          | 企业私有化LLM应用（如金融、医疗）&lt;button class='citation-flag' data-index='9'&gt;  | 完全私有化，适合敏感数据场景&lt;button class='citation-flag' data-index='9'&gt;                                       | 社区支持较弱，更新频率低&lt;button class='citation-flag' data-index='9'&gt;                                           | **CPU**: 8核+&lt;br&gt;**内存**: 32GB+&lt;br&gt;**显卡**: 16GB+（运行大模型） | &lt;button class='citation-flag' data-index='9'&gt;                  |
| **Coze**          | 插件支持、工作流编排、低代码开发                                            | 个人开发者或C端产品快速迭代             | 易用性强，适合快速开发C端应用（如聊天机器人）                            | 依赖平台生态，定制化能力有限                                            | **CPU**: 4核+&lt;br&gt;**内存**: 8GB            | （推测，知识库未提及） |

###**三、大模型社区**
| 社区名称         | 开源性       | 主要支持者           | 应用场景                     | 生态系统特点                           |
|------------------|--------------|----------------------|------------------------------|----------------------------------------|
| Hugging Face     | 完全开源     | 独立公司（Hugging Face） | NLP、多模态、研究与生产       | 丰富的模型库、强大的社区支持、易用工具 |
| TensorFlow       | 部分开源     | Google               | 深度学习、生产环境部署        | 强大的分布式训练支持、工业级应用      |
| PyTorch          | 完全开源     | Meta（Facebook）     | 研究与开发、灵活性高          | 动态计算图、广泛的研究支持            |
| OpenAI           | 部分闭源     | OpenAI               | 生成式AI、商业应用            | GPT系列模型、API服务为主              |
| Alibaba DAMO     | 部分开源     | 阿里巴巴             | 多语言、多模态、企业级应用    | 通义千问系列、云服务集成              |
| NVIDIA NeMo      | 部分开源     | NVIDIA               | 语音处理、对话系统            | 高性能GPU优化、模块化设计             |
| PaddlePaddle     | 完全开源     | 百度                 | 工业应用、中文支持            | 飞桨框架、丰富的中文资源              |
| Stable Diffusion | 完全开源     | Stability AI         | 图像生成、艺术创作            | 社区驱动、插件生态丰富                |
| LangChain        | 完全开源     | 社区驱动             | 大模型应用开发、链式任务      | 灵活的模块化设计、支持多种模型        |


### **四、大模型微调框架**
| **工具**         | **核心功能**                                                                 | **支持模型**                                                                 | **算法/技术**                                                                 | **适用场景**                                                                 | **优点**                                                                 | **缺点**                                                                 | **硬件需求**                                                                 | 
|------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| **XTuner**       | 轻量级微调框架，支持指令微调、DPO、PPO等&lt;button class='citation-flag' data-index='3'&gt;                                | LLaMA、Qwen、Mistral等主流开源模型&lt;button class='citation-flag' data-index='3'&gt;                                      | LoRA、Prefix-Tuning、DeepSpeed ZeRO&lt;button class='citation-flag' data-index='3'&gt;                                    | 中小规模数据集（如文本分类、对话生成）&lt;button class='citation-flag' data-index='3'&gt;                                  | 资源占用低（单卡8GB显存可运行7B模型）；支持快速实验迭代&lt;button class='citation-flag' data-index='3'&gt;                | 社区活跃度低，文档较少&lt;button class='citation-flag' data-index='3'&gt;                                               | **GPU**: 消费级显卡（如RTX 3060）&lt;br&gt;**显存**: 8GB+&lt;br&gt;**内存**: 16GB+       | &lt;button class='citation-flag' data-index='3'&gt;                  |
| **Firefly**      | 多范式微调工具，支持预训练、指令微调、DPO&lt;button class='citation-flag' data-index='5'&gt;                               | LLaMA-3、Qwen2、Falcon等&lt;button class='citation-flag' data-index='5'&gt;                                               | LoRA、DoRA、QLoRA、梯度检查点优化&lt;button class='citation-flag' data-index='5'&gt;                                      | 企业级大规模训练（如多任务指令对齐、领域适配）&lt;button class='citation-flag' data-index='5'&gt;                         | 模块化设计，支持分布式训练；兼容Hugging Face生态&lt;button class='citation-flag' data-index='5'&gt;                      | 配置复杂，需熟悉PyTorch和DeepSpeed&lt;button class='citation-flag' data-index='5'&gt;                                    | **GPU**: NVIDIA A100/V100&lt;br&gt;**显存**: 24GB+（70B模型需40GB+）&lt;br&gt;**内存**: 64GB+ | &lt;button class='citation-flag' data-index='5'&gt;                  |
| **unsloth**      | 速度与显存优化工具，支持低资源微调&lt;button class='citation-flag' data-index='8'&gt;                                       | Llama-3、Mistral、Qwen1.5等&lt;button class='citation-flag' data-index='8'&gt;                                            | 4-bit量化、梯度累积优化、FlashAttention&lt;button class='citation-flag' data-index='8'&gt;                                | 资源受限场景（如单卡微调65B模型）&lt;button class='citation-flag' data-index='8'&gt;                                      | 显存占用降低50%；训练速度提升2-3倍&lt;button class='citation-flag' data-index='8'&gt;                                     | 仅支持特定模型架构，灵活性有限&lt;button class='citation-flag' data-index='8'&gt;                                        | **GPU**: RTX 3090/4090&lt;br&gt;**显存**: 8GB+（量化后）&lt;br&gt;**内存**: 32GB+         | &lt;button class='citation-flag' data-index='8'&gt;                  |
| **LLaMA Factory**| 一站式微调平台，集成数据预处理到部署&lt;button class='citation-flag' data-index='10'&gt;                                    | LLaMA全系列、Pythia、MPT&lt;button class='citation-flag' data-index='10'&gt;                                              | LoRA、IA³、P-Tuning v2、AutoGPTQ量化&lt;button class='citation-flag' data-index='10'&gt;                                 | 快速上手（如个人开发者微调对话模型）&lt;button class='citation-flag' data-index='10'&gt;                                   | 提供WebUI界面；支持多任务可视化监控&lt;button class='citation-flag' data-index='10'&gt;                                  | 定制化能力弱，复杂场景需二次开发&lt;button class='citation-flag' data-index='10'&gt;                                     | **GPU**: 8GB+（7B模型）&lt;br&gt;**内存**: 16GB+&lt;br&gt;**存储**: 50GB+（缓存数据）     | &lt;button class='citation-flag' data-index='10'&gt;                 |
| **PEFT**         | 参数高效微调库（Hugging Face官方工具）&lt;button class='citation-flag' data-index='9'&gt;                                   | 所有Hugging Face Transformers模型&lt;button class='citation-flag' data-index='9'&gt;                                      | LoRA、Prefix-Tuning、Prompt-Tuning、IA³&lt;button class='citation-flag' data-index='9'&gt;                               | 研究场景（如对比不同微调算法效果）&lt;button class='citation-flag' data-index='9'&gt;                                      | 无缝集成Hugging Face生态；支持多种SOTA算法&lt;button class='citation-flag' data-index='9'&gt;                            | 需自行搭建训练流程，功能较分散&lt;button class='citation-flag' data-index='9'&gt;                                        | **GPU**: 根据模型规模选择&lt;br&gt;**显存**: 16GB+（建议）                         | &lt;button class='citation-flag' data-index='9'&gt;                  |
| **GaLore**       | 低秩适应优化算法（需结合其他工具使用）&lt;button class='citation-flag' data-index='7'&gt;                                   | 通用（需适配到工具如Firefly）&lt;button class='citation-flag' data-index='7'&gt;                                           | 低秩矩阵分解、梯度压缩&lt;button class='citation-flag' data-index='7'&gt;                                                | 超大规模模型（如65B模型）的轻量化微调&lt;button class='citation-flag' data-index='7'&gt;                                  | 参数效率提升30%-50%；显存占用更低&lt;button class='citation-flag' data-index='7'&gt;                                      | 独立性差，需集成到现有框架&lt;button class='citation-flag' data-index='7'&gt;                                            | **GPU**: 24GB+显存（如A100）&lt;br&gt;**内存**: 64GB+                              | &lt;button class='citation-flag' data-index='7'&gt;                  |
| **LongLoRA**     | 上下文扩展工具（支持超长序列微调）&lt;button class='citation-flag' data-index='7'&gt;                                       | LLaMA、Mistral等支持RoPE编码的模型&lt;button class='citation-flag' data-index='7'&gt;                                      | 位置插值、分段训练、内存优化&lt;button class='citation-flag' data-index='7'&gt;                                           | 长文本生成（如法律文书、科研论文）&lt;button class='citation-flag' data-index='7'&gt;                                     | 上下文长度扩展至32768 tokens；无需重新预训练&lt;button class='citation-flag' data-index='7'&gt;                           | 兼容性有限，需调整模型架构&lt;button class='citation-flag' data-index='7'&gt;                                            | **GPU**: 40GB+显存（如A100）&lt;br&gt;**内存**: 128GB+&lt;br&gt;**存储**: 1TB+（缓存）   | &lt;button class='citation-flag' data-index='7'&gt;                  |
| **Axolotl**      | 多模型支持微调工具，配置灵活&lt;button class='citation-flag' data-index='4'&gt;                                             | Llama、Pythia、Falcon、MPT等&lt;button class='citation-flag' data-index='4'&gt;                                            | LoRA、QLoRA、DeepSpeed、混合精度训练&lt;button class='citation-flag' data-index='4'&gt;                                   | 研究与生产环境（如医疗、金融领域适配）&lt;button class='citation-flag' data-index='4'&gt;                                 | 支持多种模型和训练范式；社区活跃&lt;button class='citation-flag' data-index='4'&gt;                                       | 文档分散，新手学习成本高&lt;button class='citation-flag' data-index='4'&gt;                                               | **GPU**: 16GB+显存（建议多卡）&lt;br&gt;**内存**: 32GB+                             | &lt;button class='citation-flag' data-index='4'&gt;                  |
。</description><guid isPermaLink="true">https://Goinghome-Chapter1.github.io/post/zhu-liu-da-mo-xing-gong-ju-da-zong-jie-%EF%BC%81%EF%BC%81.html</guid><pubDate>Fri, 28 Feb 2025 02:52:29 +0000</pubDate></item><item><title>LLM系列文章</title><link>https://Goinghome-Chapter1.github.io/post/LLM-xi-lie-wen-zhang.html</link><description>0 提示词工程：https://zhuanlan.zhihu.com/p/672722112
0 国内大模型 https://github.com/HqWu-HITCS/Awesome-Chinese-LLM?tab=readme-ov-file#11-%E6%96%87%E6%9C%ACllm%E6%A8%A1%E5%9E%8B
1 服务器部署deep seek：https://www.cnblogs.com/menkeyi/p/18707043      （框架vLLM）
2 unsloth：https://docs.unsloth.ai/get-started/unsloth-notebooks      （官方文档）
3 文本分类微调：https://github.com/timothelaborie/text_classification_scripts/blob/main/unsloth_classification.ipynb。</description><guid isPermaLink="true">https://Goinghome-Chapter1.github.io/post/LLM-xi-lie-wen-zhang.html</guid><pubDate>Fri, 21 Feb 2025 11:36:29 +0000</pubDate></item></channel></rss>